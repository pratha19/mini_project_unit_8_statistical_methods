{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics Ib - Frequentism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second Frequentist inference mini-project! Over the course of working on this mini-project and the previous frequentist mini-project, you'll learn the fundamental concepts associated with frequentist inference. The following list includes the topics you will become familiar with as you work through these two mini-projects:\n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate confidence intervals and p-values\n",
    "* how those confidence intervals and p-values allow you to perform hypothesis (or A/B) tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For working through this notebook, you are expected to have a very basic understanding of:\n",
    "* what a random variable is\n",
    "* what a probability density function (pdf) is\n",
    "* what the cumulative density function is\n",
    "* a high-level sense of what the Normal distribution\n",
    "\n",
    "If these concepts are new to you, please take a few moments to Google these topics in order to get a sense of what they are and how you might use them.\n",
    "\n",
    "These two notebooks were designed to bridge the gap between having a basic understanding of probability and random variables and being able to apply these concepts in Python. This second frequentist inference mini-project focuses on a real-world application of this type of inference to give you further practice using these concepts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used only data from a known normal distribution. You'll now tackle real data, rather than simulated data, and answer some relevant real-world business problems using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital medical charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that a hospital has hired you as their data analyst. An administrator is working on the hospital's business operations plan and needs you to help them answer some business questions. This mini-project, as well as the bootstrap and Bayesian inference mini-projects also found in this unit are designed to illustrate how each of the inferential statistics methods have their uses for different use cases. In this assignment notebook, you're going to use frequentist statistical inference on a data sample to answer the questions:\n",
    "* has the hospital's revenue stream fallen below a key threshold?\n",
    "* are patients with insurance really charged different amounts than those without?\n",
    "Answering that last question with a frequentist approach makes some assumptions, or requires some knowledge, about the two groups. In the next mini-project, you'll use bootstrapping to test that assumption. And in the final mini-project of the unit, you're going to create a model for simulating _individual_ charges (not a sampling distribution) that the hospital can use to model a range of scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use some data on medical charges obtained from [Kaggle](https://www.kaggle.com/easonlai/sample-insurance-claim-prediction-dataset). For the purposes of this exercise, assume the observations are the result of random sampling from our one hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import scipy.stats\n",
    "from numpy.random import seed\n",
    "medical = pd.read_csv('data/insurance2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>insuranceclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges  insuranceclaim\n",
       "0   19    0  27.900         0       1       3  16884.92400               1\n",
       "1   18    1  33.770         1       0       2   1725.55230               1\n",
       "2   28    1  33.000         3       0       2   4449.46200               0\n",
       "3   33    1  22.705         0       0       1  21984.47061               0\n",
       "4   32    1  28.880         0       0       1   3866.85520               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Plot the histogram of charges and calculate the mean and standard deviation. Comment on the appropriateness of these statistics for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the histogram of charges #\n",
    "_ = plt.hist(medical['charges'])\n",
    "_ = plt.xlabel('charges')\n",
    "_ = plt.ylabel('number of patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean of hospital charges is:  13270.422265141257\n",
      "\n",
      "sample std of hospital charges is:  12105.484975561605\n"
     ]
    }
   ],
   "source": [
    "#calculate the mean and standard deviation\n",
    "sample_mean= np.mean(medical['charges'])\n",
    "print('sample mean of hospital charges is: ', sample_mean)\n",
    "sample_std= np.std(medical['charges'])\n",
    "print('\\nsample std of hospital charges is: ', sample_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment on the appropriateness of these statistics for the data.\n",
    "\n",
    "#The distribution is clearly not normal and is right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ The administrator is concerned that the actual average charge has fallen below 12000, threatening the hospital's operational model. On the assumption that these data represent a random sample of charges, how would you justify that these data allow you to answer that question? And what would be the most appropriate frequentist test, of the ones discussed above, to apply?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A: As seen before the distribution of the hospital charges is not normal, so to model it as a normal or t distribution, we need to verfiy certain things:__\n",
    "1. __Whether the sampling was random: as stated above, for the purposes of this exercise, assuming the observations are the result of random sampling from one hospital.__\n",
    "2. __Is the distribution normal or n>=30: the distribution is not normal but n>=30 so we can assume that the sample distribution of the sample means will be normally distributed.__\n",
    "3. __Are the samples independent of each other: Yes, we can assume that here since each patient's expenditure will be independent of each other and also we can use the 10% rule that the number of patients sampled here are only 10% or less of the total number of patients visiting the hospital.__\n",
    "\n",
    "__Now, since we are not given with the standard deviation of the actual population, we need to use t-statistic to avoid under estimating the standard deviation. We can use hypothesis test with t-statistic to find out if the average charge has fallen below 12000.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Given the nature of the administrator's concern, what is the appropriate confidence interval in this case? A one-sided or two-sided interval? Calculate the critical value and the relevant 95% confidence interval for the mean and comment on whether the administrator should be concerned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A: If the average charge has actually fallen below 12000 then the administrator will be very concerned because that can threaten the hospital's operational model.So, we need to use a high confidence leve here. Let's use 95%. And since the concern is only limited to if the charge has fallen below a threshold, we need to calculate a one sided interval. __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the population std by using n-1 in the denominator\n",
    "pop_std= np.std(medical['charges'], ddof=1)\n",
    "#sample size n\n",
    "n= len(medical['charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical t value for this sample distribution for 95% confidence is: -1.65\n"
     ]
    }
   ],
   "source": [
    "#Calculate the critical value and the relevant 95% confidence interval for the mean \n",
    "\"\"\"Calculating the critical t value; We need to pass the df argument for using the t distribution. The degrees of freedom in this \n",
    "case is n-1. And using 0.05 as the probability because we are looking at the left tail only.\"\"\"\n",
    "\n",
    "t_value=(t.ppf(0.05, n-1, loc=sample_mean, scale=pop_std)-sample_mean)/pop_std\n",
    "t_value=round(t_value,2)\n",
    "print('The critical t value for this sample distribution for 95% confidence is: '+str(t_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOE by using t statistic is: -546.2612996208757\n",
      "\n",
      "Thus, 95% of the times we can expect the mean to be greater than 12724.160965520381\n"
     ]
    }
   ],
   "source": [
    "#Calculate the critical value and the relevant 95% confidence interval for the mean \n",
    "\n",
    "\"\"\" We need to calculate the minimum value given by the above critical t value such that this minimum value and all values\n",
    "below it will have a <=5% chance of occurence.\"\"\"\n",
    "#calculating standard error\n",
    "SE= pop_std/np.sqrt(n) \n",
    "MOE_t= t_value*SE\n",
    "print('MOE by using t statistic is:', MOE_t)\n",
    "print('\\nThus, 95% of the times we can expect the mean to be greater than '+ str(sample_mean+MOE_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As observed above, 95% of the times we would expect the population mean to be above 12724.16 and since\\nthat is much greater than the suspected 12000, the administrator need not be concerned that the\\nmean has fallen below 12000. '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comment on whether the administrator should be concerned\n",
    "\"\"\" As observed above, 95% of the times we would expect the population mean to be above 12724.16 and since\n",
    "that is much greater than the suspected 12000, the administrator need not be concerned that the\n",
    "mean has fallen below 12000. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The administrator then wants to know whether people with insurance really are charged a different amount to those without.\n",
    "\n",
    "__Q:__ State the null and alternative hypothesis here. Use the _t_-test for the difference between means where the pooled standard deviation of the two groups is given by\n",
    "\\begin{equation}\n",
    "s_p = \\sqrt{\\frac{(n_0 - 1)s^2_0 + (n_1 - 1)s^2_1}{n_0 + n_1 - 2}}\n",
    "\\end{equation}\n",
    "\n",
    "and the *t* test statistic is then given by\n",
    "\n",
    "\\begin{equation}\n",
    "t = \\frac{\\bar{x}_0 - \\bar{x}_1}{s_p \\sqrt{1/n_0 + 1/n_1}}.\n",
    "\\end{equation}\n",
    "\n",
    "What assumption, or assumptions, are we making here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A: Not sure if I am asnwering this correctly, but I guess we can design two hypotheses here:__\n",
    "1. __Null hypothesis H0: People with insurance are charged the same amount as the people without insurance. We assume that H0 is true and then calculate the p_value and check if it lies below or above our significance level. __\n",
    "2. __Alternative hypothesis: People with insurance are charged a different amount than the people with insurance.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Perform this hypothesis test both manually, using the above formulae, and then using the appropriate function from [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) (hint, you're looking for a function to perform a _t_-test on two independent samples). For the manual approach, calculate the value of the test statistic and then its probability (the p-value). Verify you get the same results from both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.89329903087671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use a significane level i.e. Alpha of 0.05 as a threshold for the p-value\n",
    "# Manual calculation\n",
    "## Listing the characteristics of the two samples\n",
    "sample1= medical[medical['insuranceclaim']==1]['charges'] #sampling people with insurance\n",
    "sample2= medical[medical['insuranceclaim']==0]['charges'] #sampling people without insurance\n",
    "\n",
    "n0= len(sample1)\n",
    "n1= len(sample2)\n",
    "\n",
    "x0= np.mean(sample1)\n",
    "x1= np.mean(sample2)\n",
    "\n",
    "s0= np.std(sample1, ddof=1)\n",
    "#s0= s0_sample/np.sqrt(n0)\n",
    "s1= np.std(sample2, ddof=1)\n",
    "#s1= s1_sample/np.sqrt(n1)\n",
    "\n",
    "#calculating the pooled standard deviation of samples 1 and 2 using the formula given above\n",
    "sp= np.sqrt(((n0-1)*s0**2+(n1-1)*s1**2)/(n0+n1-2))\n",
    "\n",
    "#calculating the t test statistic using the formula given above\n",
    "t_stat= (x0-x1)/(sp*np.sqrt(1/n0+1/n1))\n",
    "\n",
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the t-value is 11.89 (which is very large), the p-value can be expected to be very small ~<0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=11.893299030876712, pvalue=4.461230231620717e-31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using scipy.stats function for performing t-test on two independent samples\n",
    "scipy.stats.ttest_ind_from_stats(x0, s0, n0, x1, s1, n1, equal_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Since the p-value is less than our significance level alpha=0.05 we can reject the null hypothesis and say with \\nconfidence that people with insurance are charged a different amount than the people with insurance. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Since the p-value is less than our significance level alpha=0.05 we can reject the null hypothesis and say with \n",
    "confidence that people with insurance are charged a different amount than the people with insurance. \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Hopefully you got the exact same numerical results. This shows that you correctly calculated the numbers by hand. Secondly, you used the correct function and that is much easier to use. All you need to do is pass it your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ In the above calculations, we assumed the sample variances were equal. We may well suspect they are not (we'll explore this in another assignment). The calculation becomes a little more complicated to do by hand in this case, but we now know of a helpful function. Check the documentation for the function to tell it not to assume equal variances and perform the test again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=13.298031957975647, pvalue=1.1105103216309438e-37)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using scipy.stats function with different variances\n",
    "scipy.stats.ttest_ind_from_stats(x0, s0, n0, x1, s1, n1, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Conceptual question: look through the documentation for statistical test functions in scipy.stats. You'll see the above _t_-test for a sample, but can you see an equivalent one for performing a *z*-test from a sample? Comment on your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A: binom_test(x[, n, p, alternative]) Perform a test that the probability of success is p. This one? __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed this project notebook, you have good hands-on experience of\n",
    "* how you can use the central limit theorem to help you apply frequentist techniques to answer questions that pertain to very non-normally distributed data from the real world\n",
    "* how to then perform inference using such data to answer business questions\n",
    "* forming a hypothesis and framing the null and alternative hypotheses\n",
    "* testing this using a _t_-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
